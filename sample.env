###################################
# JPO GeoJsonConverter Docker Environment File #
###################################
# WARNING! The contents of this file may be sensitive. Take care not to add to source control.
#
# Instructions:
#   Rename this file from `sample.env` to `.env` and Docker will automatically pick up the variables.
#
# Description:
#   This file aggregates all the variables used in docker-compose.yml for ease of use. Variables are
#   prefixed with the format DESTINATION_MESSAGETYPE_ to provide guidance. Some variables are filled
#   out with commonly used values.
###################################

####################
# General Properties

# (Required) The IP address of Docker host machine which can be found by running "ifconfig"
# Hint: look for "inet addr:" within "eth0" or "en0" for OSX
DOCKER_HOST_IP=

# GitHub properties for pulling the latest version of the JPO-ODE at build time
# NOTE: These variables are only required for building the geojson-converter image, not for running the image
MAVEN_GITHUB_TOKEN=
MAVEN_GITHUB_ORG=usdot-jpo-ode

# Docker compose restart policy: https://docs.docker.com/engine/containers/start-containers-automatically/
RESTART_POLICY="no"

# Available profiles:
# - all
#   - geojson_base
#       - geojson_converter
#   - geojson_cc_base
#   - mongo_full
#       - mongo
#       - mongo_express
#   - kafka_full
#       - kafka
#       - kafka_setup
#       - kafka_ui
#       - kafka_schema_registry
#   - kafka_connect_standalone
#       - kafka
#       - mongo
#       - kafka_connect
#  - kafka_connect
#       - kafka_connect
# EXAMPLE: COMPOSE_PROFILES=kafka_connect_standalone,kafka_ui,mongo_express
COMPOSE_PROFILES=geojson_full,kafka,kafka_setup,kafka_ui

# Feature geometry output mode
# Options are GEOJSON_ONLY or WKT, defaults to GEOJSON_ONLY if nothing is specified
# WKT mode will still generate geoJSON output
GEOMETRY_OUTPUT_MODE=

#########################
# Kafka and Confluent Cloud Properties - START

# The type of Kafka broker to connect to. If set to "CONFLUENT", the broker will be Confluent Cloud. Otherwise, it will be a local Kafka broker.
KAFKA_TYPE=
KAFKA_LINGER_MS=1
KAFKA_BOOTSTRAP_SERVERS=${DOCKER_HOST_IP}:9092
KAFKA_LOG_RETENTION_HOURS=3
KAFKA_LOG_RETENTION_BYTES=10737418240 # 10GB

# Local Kafka broker properties - you can override these if you want, but the defaults should be fine for normal use
# The application will not boot if these environment variables are set to empty strings (e.g. KAFKA_BATCH_SIZE=)
KAFKA_COMPRESSION_TYPE="zstd"
KAFKA_BATCH_SIZE=16384
KAFKA_ACKS="all"
KAFKA_RETRIES=0
KAFKA_KEY_SERIALIZER="org.apache.kafka.common.serialization.StringSerializer"
KAFKA_VALUE_SERIALIZER="org.apache.kafka.common.serialization.StringSerializer"
KAFKA_PARTITIONER_CLASS="org.apache.kafka.clients.producer.internals.DefaultPartitioner"

# Variables for creating kafka topics:
KAFKA_TOPIC_PARTITIONS=1
KAFKA_TOPIC_REPLICAS=1
KAFKA_TOPIC_MIN_INSYNC_REPLICAS=1
KAFKA_TOPIC_RETENTION_MS=300000
KAFKA_TOPIC_DELETE_RETENTION_MS=3600000
KAFKA_TOPIC_CREATE_ODE=true                 # Create topics for ODE
KAFKA_TOPIC_CREATE_GEOJSONCONVERTER=true    # Create topics for GeoJSON Converter
KAFKA_TOPIC_CREATE_CONFLICTMONITOR=true     # Create topics for Conflict Monitor
KAFKA_TOPIC_CREATE_DEDUPLICATOR=false       # Create topics for Deduplicator
KAFKA_TOPIC_CREATE_MECDEPOSIT=false         # Create topics for MecDeposit
# Relative path to the Kafka topic yaml configuration script, upper level directories are supported
# NOTE: This script is used to create kafka topics
KAFKA_TOPIC_CONFIG_RELATIVE_PATH="./jikkou/kafka-topics-values.yaml"

# Set to Confluent Cloud access key and secret values for SASL authentication
CONFLUENT_KEY=
CONFLUENT_SECRET=

# Kafka and Confluent Cloud Properties - END
#########################

#########################
# JPO-ODE Specific Properties - START

# These are optional
DATA_SIGNING_ENABLED_RSU=
DATA_SIGNING_ENABLED_SDW=
DEFAULT_SNMP_PROTOCOL=

# ODE Monitoring
ODE_TIM_INGEST_MONITORING_ENABLED=false
# The interval is measured in seconds. 60 seconds is a sane default for local monitoring, but you may want to increase
# the interval to 3600 (1 hour) or more for production monitoring to reduce the noise in logs for healthy systems
ODE_TIM_INGEST_MONITORING_INTERVAL=60

# Enable the STOMP Exporter
ODE_STOMP_EXPORTER_ENABLED=false

# JPO-ODE Specific Properties - END
#########################

#########################
# ACM Logging Properties - START

ADM_LOG_TO_FILE=false
ADM_LOG_TO_CONSOLE=true
ADM_LOG_LEVEL=INFO

# ACM Logging Properties - END
#########################

#########################
# MongoDB Properties - START

# NOTE: Must set a password for the container to start up properly
MONGO_IP=${DOCKER_HOST_IP}
MONGO_DB_NAME=CV

# Generate a random string for the MongoDB keyfile using the following command:
# $ openssl rand -base64 32
MONGO_DB_KEYFILE_STRING=replacethisstring

MONGO_ADMIN_DB_USER=admin
MONGO_ADMIN_DB_PASS=replace_me

MONGO_READ_WRITE_USER=ode
MONGO_READ_WRITE_PASS=replace_me

MONGO_READ_USER=user
MONGO_READ_PASS=replace_me

MONGO_EXPORTER_USERNAME=export
MONGO_EXPORTER_PASSWORD=replace_me

MONGO_EXPRESS_USER=${MONGO_ADMIN_DB_USER}
MONGO_EXPRESS_PASS=${MONGO_ADMIN_DB_PASS}

MONGO_PORT=27017
MONGO_DATA_RETENTION_SECONDS=5184000
MONGO_ASN_RETENTION_SECONDS=86400


MONGO_DATABASE_STORAGE_COLLECTION_NAME=MongoStorage
MONGO_DATABASE_SIZE_GB=1000
MONGO_DATABASE_SIZE_TARGET_PERCENT=0.8
MONGO_DATABASE_DELETE_THRESHOLD_PERCENT=0.9
MONGO_DATABASE_MAX_TTL_RETENTION_SECONDS=5184000
MONGO_DATABASE_MIN_TTL_RETENTION_SECONDS=604800
MONGO_DATABASE_COMPACTION_TRIGGER_PERCENT=MONGO_DATABASE_COMPACTION_TRIGGER_PERCENT
MONGO_ENABLE_STORAGE_RECORD=true
MONGO_ENABLE_DYNAMIC_TTL=true



# Relative path to the MongoDB init script, upper level directories are supported
MONGO_SETUP_SCRIPT_RELATIVE_PATH="./mongo/setup_mongo.sh"
MONGO_INIT_REPLICAS_SCRIPT_RELATIVE_PATH="./mongo/init_replicas.js"
MONGO_CREATE_INDEXES_SCRIPT_RELATIVE_PATH="./mongo/create_indexes.js"
MONGO_MANAGE_VOLUMES_SCRIPT_RELATIVE_PATH="./mongo/manage_volume.js"

# MongoDB Properties - END
#########################

#########################
# Kafka Connect Properties - START

# NOTE: Required variables: [MONGODB, KAFKA]
CONNECT_URL=http://${DOCKER_HOST_IP}:8083
# Kafka connect log level
CONNECT_LOG_LEVEL=ERROR

CONNECT_TASKS_MAX=1                     # Number of concurrent tasks to configure on kafka connectors
CONNECT_CREATE_ODE=true                 # Create kafka connectors to MongoDB for ODE
CONNECT_CREATE_GEOJSONCONVERTER=true    # Create kafka connectors to MongoDB for GeoJSON Converter
CONNECT_CREATE_CONFLICTMONITOR=true     # Create kafka connectors to MongoDB for Conflict Monitor
CONNECT_CREATE_DEDUPLICATOR=false       # Create kafka connectors to MongoDB for Deduplicator
CONNECT_CREATE_MECDEPOSIT=false         # Create kafka connectors to MongoDB for MecDeposit
# Relative path to the Kafka Connector yaml configuration script, upper level directories are supported
# NOTE: This script is used to create kafka connectors
CONNECT_CONFIG_RELATIVE_PATH="./jikkou/kafka-connectors-values.yaml"

# Kafka Connect - END
#########################